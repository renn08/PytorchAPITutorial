{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f8649074-1993-4d81-8403-c82a937b7acb",
      "metadata": {
        "id": "f8649074-1993-4d81-8403-c82a937b7acb"
      },
      "source": [
        "# Pytorch Tutorial\n",
        "\n",
        "In this tutorial we will walk through some examples of the Pytorch API that you might find useful on your assignments. \n",
        "\n",
        "We will walk through an example of using the Pytorch API to demonstrate its functionality:\n",
        "\n",
        "- Implementing a simple neural network using Pytorch from API resources\n",
        "\n",
        "This notebook contains two sections: \n",
        "\n",
        "1. Setup\n",
        "2. Building networks from scratch using Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68f4cb38-67ee-424a-b999-2310ad8091c3",
      "metadata": {
        "id": "68f4cb38-67ee-424a-b999-2310ad8091c3"
      },
      "source": [
        "## Pytorch API Explanation\n",
        "\n",
        "As a brief overview, we can conceive of Pytorch as offering three levels of abstraction:\n",
        "\n",
        "| Level   | API             | Flexibility | Convenience |\n",
        "|---------------------|-----------------|-------------|-------------|\n",
        "| 1 | Barebone        | High        | Low         |\n",
        "| 2 | `nn.Module`     | High        | Medium      |\n",
        "| 3 | `nn.Sequential` | Low         | High        |\n",
        "\n",
        "\n",
        "Previously we have worked with the Level-1 Barebones Pytorch API by manually defining forward-backward passes and implementing all logic ourselves.\n",
        "\n",
        "At Level-2 Pytorch's `nn.Module` allows us to encapsulate the arbitrary logic for a generic neural network architecture. \n",
        "Using `nn.Module` one can define \"components\" of a neural network such as a ResNet block or something as simple as a \"flatten\" operation by defining a `forward()` pass.\n",
        "These `nn.Module` objects can then be composed together to perform the operations we desire in our overall network with Pytorch's libraries able to manage optimization and updates.\n",
        "[You can find more details about the nn.Module API here.](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)\n",
        "\n",
        "At Level-3, we can compose several Pytorch Modules using `nn.Sequential` in order to make our logic even simpler. \n",
        "`nn.Sequential` encapsulates the composition of several `nn.Module` objects, automatically applying the forward-passes end-to-end. \n",
        "[You can find more details about the nn.Sequential API here](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)\n",
        "\n",
        "Importantly, Level-3 also automatically interfaces with Pytorch optimization libraries to simplify training code as well.\n",
        "\n",
        "We will use all three levels of abstraction in our assignments. However, this tutorial focuses on both `nn.Module` and `nn.Sequential` abstraction layers as a tool for building neural networks.\n",
        "\n",
        "You can see that in A4 we call the `nn.Sequential` constructor in `FCOSPredictionNetwork.__init__()` you will learn what objects to pass to the `nn.Sequential` constructor in this notebook. NOTE: all of our models inherit from `nn.Module` to take advantage of the Pytorch API.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb94d8e0-737b-4d76-a1f7-6614db277dba",
      "metadata": {
        "id": "eb94d8e0-737b-4d76-a1f7-6614db277dba"
      },
      "source": [
        "# I. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0aa8f9fc-8d2c-4e35-be7e-b4e1639c2490",
      "metadata": {
        "id": "0aa8f9fc-8d2c-4e35-be7e-b4e1639c2490"
      },
      "source": [
        "### Load Packages\n",
        "Here we will load the relevant torch packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e34dedbd-66dc-4084-b4c4-9789e23b2bc2",
      "metadata": {
        "id": "e34dedbd-66dc-4084-b4c4-9789e23b2bc2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "os.environ[\"TZ\"] = \"US/Eastern\"\n",
        "time.tzset()\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "# for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cb39a0c-6b4c-4a34-9196-5102a8e4d34c",
      "metadata": {
        "id": "5cb39a0c-6b4c-4a34-9196-5102a8e4d34c"
      },
      "source": [
        "We will use the GPU to accelerate our computation. Run this cell to make sure you are using a GPU.\n",
        "\n",
        "We will be using `torch.float = torch.float32` for data and `torch.long = torch.int64` for labels.\n",
        "\n",
        "Please refer to https://pytorch.org/docs/stable/tensor_attributes.html#torch-dtype for more details about data types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce8f5e3b-af3d-4d1e-88f7-dd32d54b3347",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce8f5e3b-af3d-4d1e-88f7-dd32d54b3347",
        "outputId": "b116ebaa-231d-4de3-d7d0-8ac119be912d"
      },
      "outputs": [],
      "source": [
        "to_float= torch.float\n",
        "to_long = torch.long\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print('Good to go!')\n",
        "    notebook_device = 'cuda'\n",
        "else:\n",
        "    print('Please set GPU via Edit -> Notebook Settings.')\n",
        "    notebook_device = 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25b42052-1e2c-473d-99aa-d984038c3d47",
      "metadata": {
        "id": "25b42052-1e2c-473d-99aa-d984038c3d47"
      },
      "source": [
        "### Load CIFAR\n",
        "We are using [torchvision.datasets.CIFAR10](https://pytorch.org/docs/stable/torchvision/datasets.html?highlight=cifar#torchvision.datasets.CIFAR10) to download the CIFAR-10 dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3533bbe-7546-44dc-bb6c-bb98af0608f4",
      "metadata": {
        "id": "d3533bbe-7546-44dc-bb6c-bb98af0608f4"
      },
      "source": [
        "We instantiate a `DataLoader` object using the function below `load_CIFAR` in order to interact with our dataset. You can observe that this step is fundementally similar to how we interact with the `VOC2007` dataset in A4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c6081d9-a7be-417b-88f0-18e3793391ea",
      "metadata": {
        "id": "6c6081d9-a7be-417b-88f0-18e3793391ea"
      },
      "outputs": [],
      "source": [
        "def load_CIFAR(path='./datasets/'):\n",
        "    NUM_TRAIN = 49000\n",
        "    # The torchvision.transforms package provides tools for preprocessing data\n",
        "    # and for performing data augmentation; here we set up a transform to\n",
        "    # preprocess the data by subtracting the mean RGB value and dividing by the\n",
        "    # standard deviation of each RGB value; we've hardcoded the mean and std.\n",
        "    transform = T.Compose([\n",
        "                  T.ToTensor(),\n",
        "                  T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "              ])\n",
        "\n",
        "    # We set up a Dataset object for each split (train / val / test); Datasets load\n",
        "    # training examples one at a time, so we wrap each Dataset in a DataLoader which\n",
        "    # iterates through the Dataset and forms minibatches. We divide the CIFAR-10\n",
        "    # training set into train and val sets by passing a Sampler object to the\n",
        "    # DataLoader telling how it should sample from the underlying Dataset.\n",
        "    cifar10_train = dset.CIFAR10(path, train=True, download=True,\n",
        "                               transform=transform)\n",
        "    \n",
        "    # This data loader object is actually what we will use to interact with our data.\n",
        "    # while the dataset object created above gives us an API for the dataset as a whole\n",
        "    # the dataloader object allows us to grab chunks of our dataset by batch_size.\n",
        "    # this is orchestrated by the sampler object we pass into the constructor\n",
        "    loader_train = DataLoader(cifar10_train, batch_size=64, \n",
        "                            sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
        "\n",
        "    cifar10_val = dset.CIFAR10(path, train=True, download=True,\n",
        "                             transform=transform)\n",
        "    loader_val = DataLoader(cifar10_val, batch_size=64, \n",
        "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
        "\n",
        "    cifar10_test = dset.CIFAR10(path, train=False, download=True, \n",
        "                              transform=transform)\n",
        "    loader_test = DataLoader(cifar10_test, batch_size=64)\n",
        "    return loader_train, loader_val, loader_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c22432c6-9d1c-4abc-8409-3738912346e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "16bd0babd9f24fd796ad8a8bbb69a965",
            "c752f7e80ed5411baab8288f652f0cc4",
            "e242bf454b4c40bc84c82b2b0e551b31",
            "9c88c020a4c54b359d8e0e25b3cd6d8a",
            "f175d5e5926243d2a25628d9231f63d4",
            "31817db2ac3f4e8cb086fa8505ce1512",
            "0be342eb74f944489211962c45c4e850",
            "ac614f283b374141abe12ea75b93626a",
            "c69b6c8050e3406e8f9be96b9ac0d314",
            "97576537353a4a3cafaab6a07e41653c",
            "f823dbf431054bbc9b108d47b006cf5f"
          ]
        },
        "id": "c22432c6-9d1c-4abc-8409-3738912346e9",
        "outputId": "0da6b2db-c051-4327-d46f-b5e9b8bef35a"
      },
      "outputs": [],
      "source": [
        "loader_train, loader_val, loader_test = load_CIFAR(path='./datasets/')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9bc4be1-4a60-4bfc-a91d-214310cdb26a",
      "metadata": {
        "id": "d9bc4be1-4a60-4bfc-a91d-214310cdb26a"
      },
      "source": [
        "# II. PyTorch Sequential API\n",
        "\n",
        "For simple models like a stack of feed forward layers, you still need to go through 3 steps: \n",
        "1. subclass `nn.Module`\n",
        "2. assign layers to class attributes in `__init__`\n",
        "3. call each layer one by one in `forward()`. \n",
        "\n",
        "**Is there a more convenient way?**\n",
        "\n",
        "Fortunately, PyTorch provides a container Module called `nn.Sequential`, which merges the above steps into one. It is not as flexible as `nn.Module`, because you cannot specify more complex topology than a feed-forward stack, but it's good enough for many use cases."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87f91205-acf3-4589-80a5-64b615485b30",
      "metadata": {
        "id": "87f91205-acf3-4589-80a5-64b615485b30"
      },
      "source": [
        "## Writing a Two-Layer Network\n",
        "Let's see how to write a two-layer fully connected network with `nn.Sequential`, and train it using a simple training-loop.\n",
        "\n",
        "We will skip advanced weight initialization for simplicity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7db33100-ecb8-4123-b49b-d77d5b9c071a",
      "metadata": {
        "id": "7db33100-ecb8-4123-b49b-d77d5b9c071a"
      },
      "outputs": [],
      "source": [
        "# We need the ability to flatten a non-1D tensor. Typically we would call nn.functional.flatten() or F.flatten() on a given tensor.\n",
        "# However, we can encapsulate this logic in a nn.Module block in order to make composing the function with other Modules easier.\n",
        "# We do this by overriding the forward pass of a nn.Module. This is all we need to do to create a new Module!\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return torch.flatten(x, start_dim=1) # 0 is the batch dimension so we flatten images at dimension 1\n",
        "    \n",
        "# Here we implement a custom Linear module to show how one might write their own!\n",
        "# Note pytorch has a Linear module class but we will do this ourselves\n",
        "\n",
        "class CustomLinear(nn.Module):\n",
        "    # All we need to do is handle the constructor by writing an __init__ function\n",
        "    # And then we need to write the forward pass for our module\n",
        "    def __init__(self, input_layer_size, output_layer_size):\n",
        "        # We have to call init on our super() class.\n",
        "        super().__init__() \n",
        "        # create our tensor of weights.\n",
        "        # we initialize our weight tensor normally-random\n",
        "        # We tell our Module that the self.weights member variable is a Parameter\n",
        "        # This will automatically apply any weight initialization or device movement\n",
        "        # We choose to perform on our Model to this specific tensor.\n",
        "        self.weights = nn.Parameter(\n",
        "            torch.randn(\n",
        "                input_layer_size, \n",
        "                output_layer_size\n",
        "                )\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # simply define the forward pass\n",
        "        # this is the matrix multiplication of our weight and our input.\n",
        "        return torch.matmul(x, self.weights)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9db30e4-323a-4fb6-88e8-7fa76d6b9af9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9db30e4-323a-4fb6-88e8-7fa76d6b9af9",
        "outputId": "5f8f8534-5c2e-47f4-87f7-32fee83c973b"
      },
      "outputs": [],
      "source": [
        "# we can then define some constants for ease.\n",
        "C, H, W = 3, 32, 32\n",
        "num_classes = 10\n",
        "\n",
        "# these hyperparameters could be generated using some other function, \n",
        "# but we will set them as constants as they are not our focus.\n",
        "hidden_layer_size = 4000\n",
        "learning_rate = 1e-2\n",
        "weight_decay = 1e-4\n",
        "momentum = 0.5\n",
        "\n",
        "# We can create an model using a list passed to the nn.Sequential constructor.\n",
        "model = [\n",
        "    Flatten(), \n",
        "    nn.Linear(C*H*W, hidden_layer_size),\n",
        "    nn.ReLU(),\n",
        "    # NOTE: Linear(hidden_layer_size, num_classes) would result in the same\n",
        "    # object as our CustomLinear construction below.\n",
        "    CustomLinear(hidden_layer_size, num_classes)\n",
        "]\n",
        "\n",
        "model = nn.Sequential(*model)\n",
        "\n",
        "print('Architecture:')\n",
        "print(model) # printing `nn.Module` shows the architecture of the module.\n",
        "\n",
        "# We can also create an identical architecture without using a list by \n",
        "# directly passing nn.Module objects to the constructor.\n",
        "model_alt = nn.Sequential(\n",
        "    Flatten(), \n",
        "    nn.Linear(C*H*W, hidden_layer_size),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden_layer_size, num_classes)\n",
        ")\n",
        "\n",
        "print(\"Model Alt Architecture:\")\n",
        "print(model_alt)\n",
        "\n",
        "# Because of Pytorch's API compatability, as long as we have defined \n",
        "# the model as a nn.Module (the super() class for nn.Sequential)\n",
        "# We can call the .parameters() method for the ENTIRE model and pass that to an optimizer. \n",
        "# This way we don't need to worry about missing parameters.\n",
        "# Also, this optimizer now handles the update for our model and \n",
        "# Pytorch will keep track of the computational graph to ensure that gradients are applied correctly\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, \n",
        "                      weight_decay=weight_decay,\n",
        "                      momentum=momentum, nesterov=True)\n",
        "\n",
        "print(\"SGD Optimizer\")\n",
        "print(optimizer)\n",
        "# The specific parameters of this optimizer are not particularly important for us at the moment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28e78928-7aed-4dcf-bb29-bad0c6509ad1",
      "metadata": {
        "id": "28e78928-7aed-4dcf-bb29-bad0c6509ad1"
      },
      "source": [
        "### A simple training loop example:\n",
        "\n",
        "Below we implement a training loop that expects an optimizer/model as well as a DataLoader class.\n",
        "\n",
        "This will hopefully show how simple training loops can become if we use the Pytorch API intelligently. This should be useful for the later stages of A4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c37346b4-c16f-4355-8af8-8780f3279785",
      "metadata": {
        "id": "c37346b4-c16f-4355-8af8-8780f3279785"
      },
      "outputs": [],
      "source": [
        "def train_sequential(model, optimizer, epochs=1, learning_rate_decay=.1, schedule=[], verbose=True):\n",
        "    \"\"\"\n",
        "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
        "\n",
        "    Inputs:\n",
        "    - model: A PyTorch Module giving the model to train.\n",
        "    - optimizer: An Optimizer object we will use to train the model\n",
        "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
        "\n",
        "    Returns: Nothing, but prints model accuracies during training.\n",
        "    \"\"\"\n",
        "    model = model.to(device=notebook_device)  # move the model parameters to CPU/GPU\n",
        "    num_iters = epochs * len(loader_train) # our DataLoader object has __len__ implemented.\n",
        "    \n",
        "    # we use the same learning rate scheduler in A4 to adjust the learning rate of our optimizer\n",
        "    lr_scheduler = optim.lr_scheduler.MultiStepLR(\n",
        "        optimizer, \n",
        "        milestones=[int(0.6 * num_iters), int(0.9 * num_iters)]\n",
        "    )\n",
        "    \n",
        "    # these are printing parameters\n",
        "    print_every = 100\n",
        "    if verbose:\n",
        "        num_prints = num_iters // print_every + 1\n",
        "    else:\n",
        "        num_prints = epochs\n",
        "    train_loss_history = []\n",
        "    \n",
        "    # Enter the for loop for each epoch we would like to train for.\n",
        "    for e in range(epochs):\n",
        "    \n",
        "        #adjust the learning rate of our optimizer.\n",
        "        lr_scheduler.step()\n",
        "        # put model to training mode\n",
        "        model.train() \n",
        "        # we can use the default python implicit iteration from the DataLoader!\n",
        "        for t, (x, y) in enumerate(loader_train):  \n",
        "            x = x.to(device=notebook_device, dtype=to_float) \n",
        "            # move to device, e.g. GPU, use our to_float/to_long variables\n",
        "            y = y.to(device=notebook_device, dtype=to_long)\n",
        "\n",
        "            # the __call__() method of a nn.Sequential calls the forward pass! It's that easy.\n",
        "            scores = model(x)\n",
        "            # here is an example of using a functional call rather than the nn.Module nn.CrossEntropyLoss\n",
        "            loss = F.cross_entropy(scores, y) \n",
        "\n",
        "            # Zero out all of the gradients for the variables which the optimizer\n",
        "            # will update.\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # This is the backwards pass: compute the gradient of the loss with\n",
        "            # respect to each  parameter of the model.\n",
        "            # This is AUTOMATICALLY computed by Pytorch because we create the \n",
        "            # nn.Sequential object and registered it with the optimizer.\n",
        "            # Loss is expected to be a pytorch scalar element with a single element\n",
        "            # During the forward pass all the operations for each element that results in loss\n",
        "            # are kept track of by Pytorch Autgrad in order to compute the gradients with respect\n",
        "            # to each parameter that impacts the loss value.\n",
        "            loss.backward()\n",
        "\n",
        "            # To keep track of our training loss we will append to the variable\n",
        "            # train_loss_history -- HOWEVER, we need to make sure pytorch doesn't\n",
        "            # keep track of the computational graph for this variable.\n",
        "            # We can register a variable as not-in-the-computational-graph\n",
        "            # by using .detatch()\n",
        "            # It is also convention to make these objects on the cpu so we do not\n",
        "            # consume GPU memory from this process.\n",
        "            train_loss_history.append(loss.detach().to('cpu'))\n",
        "\n",
        "            # Actually update the parameters of the model using the gradients\n",
        "            # computed by the backwards pass.\n",
        "            # once again this update step is handled automatically by Pytorch AFTER \n",
        "            # we have called loss.backward() to compute the gradients for each learnable parameter.\n",
        "            optimizer.step()\n",
        "\n",
        "        # Printing steps below.\n",
        "        num_correct = 0\n",
        "        num_samples = 0\n",
        "        # Set the model into evaluation mode\n",
        "        model.eval()\n",
        "\n",
        "        # Do not compute the computational graph for these operations\n",
        "        print(\"========== VALIDATION SET EVALUATION ==========\")\n",
        "        with torch.no_grad():\n",
        "            for x, y in loader_val:\n",
        "                x = x.to(device=notebook_device, dtype=to_float)\n",
        "                y = y.to(device=notebook_device, dtype=to_long)\n",
        "                # compute the logits of our model\n",
        "                scores = model(x)\n",
        "                _, preds = scores.max(1)\n",
        "                num_correct += (preds == y).sum()\n",
        "                num_samples += preds.size(0)\n",
        "                acc = float(num_correct)/num_samples\n",
        "\n",
        "            print(f\"Got {num_correct} / {num_samples} correct {(100*acc):.2f}\")\n",
        "\n",
        "    # Test set evaluation:\n",
        "\n",
        "    print(\"========== TEST SET EVALUATION ==========\")\n",
        "    # Printing steps below.\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    # Set the model into evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Do not compute the computational graph for these operations\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader_test:\n",
        "            x = x.to(device=notebook_device, dtype=to_float)\n",
        "            y = y.to(device=notebook_device, dtype=to_long)\n",
        "            # compute the logits of our model\n",
        "            scores = model(x)\n",
        "            _, preds = scores.max(1)\n",
        "            num_correct += (preds == y).sum()\n",
        "            num_samples += preds.size(0)\n",
        "            acc = float(num_correct)/num_samples\n",
        "\n",
        "        print(f\"Got {num_correct} / {num_samples} correct {(100*acc):.2f}\")\n",
        "\n",
        "    return train_loss_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abffb8b8-ec19-43bc-9043-ed806e2aa466",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "abffb8b8-ec19-43bc-9043-ed806e2aa466",
        "outputId": "e5db190e-de60-460f-ef24-fe1fff8e33af"
      },
      "outputs": [],
      "source": [
        "# We can now see the training for our simple two-layer network using the training loop above:\n",
        "train_loss_history = train_sequential(model, optimizer) # feel free to change the hyperparameters for fun!\n",
        "print(\"TRAIN LOSS HISTORY\")\n",
        "plt.plot(train_loss_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gnIp-t5Z3Lpk",
      "metadata": {
        "id": "gnIp-t5Z3Lpk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "PytorchTutorial.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0be342eb74f944489211962c45c4e850": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16bd0babd9f24fd796ad8a8bbb69a965": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c752f7e80ed5411baab8288f652f0cc4",
              "IPY_MODEL_e242bf454b4c40bc84c82b2b0e551b31",
              "IPY_MODEL_9c88c020a4c54b359d8e0e25b3cd6d8a"
            ],
            "layout": "IPY_MODEL_f175d5e5926243d2a25628d9231f63d4"
          }
        },
        "31817db2ac3f4e8cb086fa8505ce1512": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97576537353a4a3cafaab6a07e41653c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c88c020a4c54b359d8e0e25b3cd6d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97576537353a4a3cafaab6a07e41653c",
            "placeholder": "​",
            "style": "IPY_MODEL_f823dbf431054bbc9b108d47b006cf5f",
            "value": " 170499072/? [00:02&lt;00:00, 61923552.91it/s]"
          }
        },
        "ac614f283b374141abe12ea75b93626a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c69b6c8050e3406e8f9be96b9ac0d314": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c752f7e80ed5411baab8288f652f0cc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31817db2ac3f4e8cb086fa8505ce1512",
            "placeholder": "​",
            "style": "IPY_MODEL_0be342eb74f944489211962c45c4e850",
            "value": ""
          }
        },
        "e242bf454b4c40bc84c82b2b0e551b31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac614f283b374141abe12ea75b93626a",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c69b6c8050e3406e8f9be96b9ac0d314",
            "value": 170498071
          }
        },
        "f175d5e5926243d2a25628d9231f63d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f823dbf431054bbc9b108d47b006cf5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
